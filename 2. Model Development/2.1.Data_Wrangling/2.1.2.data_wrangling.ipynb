{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling \n",
    "\n",
    "Data Wrangling using Pandas for data analysis and manipulation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store data as Local Variable \n",
    "\n",
    "Using `data_frame` (Pandas Object) to structure tabular data into an appropriate format. It laods the complete data in memory to be ready for preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"2.1.2.cardiovascular_disease_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Values \n",
    "\n",
    "Deals with null values using `isnull().sum()` method to return all null values in any column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "age            0\n",
       "gender         0\n",
       "height         0\n",
       "weight         0\n",
       "ap_hi          0\n",
       "ap_lo          0\n",
       "cholesterol    0\n",
       "gluc           0\n",
       "smoke          0\n",
       "alco           0\n",
       "active         0\n",
       "cardio         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicates \n",
    "The presence of duplicates can effect the ML model by reducing data diversity and representativeness, potentially leading to overfitting or biased models. \n",
    "\n",
    "Using `duplicated().sum()` method returns the count of duplicate rows in data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `drop_duplicates()` method stores the data back in data_frame with duplicates removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = data_frame.drop_duplicates()\n",
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Outliers\n",
    "The removal of outliers is neccessary as it can skew analysis on numerical columns. The 25th and 75th quartile on numerical data is used to get the inter-quartile range below, allowing the estimation to an acceptable range and values outside the range can be filtered out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    66414.000000\n",
      "mean        94.062065\n",
      "std        181.418988\n",
      "min          0.000000\n",
      "25%         80.000000\n",
      "50%         80.000000\n",
      "75%         90.000000\n",
      "max      10000.000000\n",
      "Name: ap_lo, dtype: float64\n",
      "Outliers of ap_lo are above 105.0 or below 65.0\n"
     ]
    }
   ],
   "source": [
    "# The column title (### - placeholder) should be changed according to the variable\n",
    "\n",
    "print(data_frame['ap_lo'].describe())\n",
    "Q1 = data_frame['ap_lo'].quantile(0.25)\n",
    "Q3 = data_frame['ap_lo'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f'Outliers of ap_lo are above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    62505.000000\n",
      "mean        81.698904\n",
      "std          7.673364\n",
      "min         65.000000\n",
      "25%         80.000000\n",
      "50%         80.000000\n",
      "75%         90.000000\n",
      "max        105.000000\n",
      "Name: ap_lo, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter to an acceptable range \n",
    "data_frame = data_frame[(data_frame['ap_lo'] >= Q1 - 1.5 * IQR) & (data_frame['ap_lo'] <= Q3 + 1.5 * IQR)]\n",
    "print(data_frame['ap_lo'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling Features to Common Range\n",
    "Scaling of features allows machine learning algorithms to easily find the optimal solution as the different scales of features would no longer influence them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the scale feature accordingly \n",
    "scale_feature = 'height'\n",
    "\n",
    "#the minimum value with space for outliers\n",
    "MIN_value = 140\n",
    "\n",
    "#the maximum value with space for outliers\n",
    "MAX_value = 185\n",
    "\n",
    "#scale features\n",
    "data_frame[scale_feature] = [(X - MIN_value) / (MAX_value - MIN_value) for X in data_frame[scale_feature]]\n",
    "\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Wrangled Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../2.2.Feature_Engineering/2.2.1.wrangled_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
